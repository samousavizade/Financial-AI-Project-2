{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Image Classification with Feedforward NN and LetNet5\n",
    "\n",
    "All libraries we introduced in the last chapter provide support for convolutional layers. We are going to illustrate the LeNet5 architecture using the most basic MNIST handwritten digit dataset, and then use AlexNet on CIFAR10, a simplified version of the original ImageNet to demonstrate the use of data augmentation.\n",
    "    LeNet5 and MNIST using Flux."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Flux.Data: DataLoader\n",
    "using Flux.Optimise: Optimiser, WeightDecay\n",
    "using Flux: onehotbatch, onecold, flatten\n",
    "using Flux.Losses: logitcrossentropy\n",
    "using Statistics, Random\n",
    "using Logging: with_logger\n",
    "using TensorBoardLogger: TBLogger, tb_overwrite, set_step!, set_step_increment!\n",
    "using ProgressMeter: @showprogress\n",
    "import MLDatasets\n",
    "import BSON\n",
    "using CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST Database\n",
    "\n",
    "The original MNIST dataset contains 60,000 images in 28x28 pixel resolution with a single grayscale containing handwritten digits from 0 to 9. A good alternative is the more challenging but structurally similar Fashion MNIST dataset that we encountered in Chapter 12 on Unsupervised Learning.\n",
    "\n",
    "We can load it in flux out of the box:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLDatasets.MNIST.download(\"MNIST/\", i_accept_the_terms_of_use=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLUtils: shuffleobs\n",
    "\n",
    "xtrain, ytrain = MLDatasets.MNIST.traindata(Float32; dir=\"MNIST/\");\n",
    "xtest, ytest = MLDatasets.MNIST.testdata(Float32; dir=\"MNIST/\");\n",
    "\n",
    "xtrain = reshape(xtrain, 28, 28, 1, :)\n",
    "xtest = reshape(xtest, 28, 28, 1, :)\n",
    "\n",
    "xtrain = xtrain[:, :, :, 1:1000];\n",
    "ytrain = ytrain[1:1000];\n",
    "xtest = xtest[:, :, :, 1:500];\n",
    "ytest = ytest[1:500];\n",
    "\n",
    "n_train = size(xtrain, 4);\n",
    "n_test = size(xtest, 4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The MNIST database has a training set of $n_train examples.\\n\")\n",
    "print(\"The MNIST database has a test set of $n_test examples.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size(xtrain), size(xtest), size(ytrain), size(ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Data\n",
    "\n",
    "### Visualize First 10 Training Images\n",
    "\n",
    "The below figure shows the first ten images in the dataset and highlights significant variation among instances of the same digit. On the right, it shows how the pixel values for an indivual image range from 0 to 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CairoMakie, Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = H = 28;\n",
    "scale = 10;\n",
    "\n",
    "nrow, ncol = 5, 5;\n",
    "f = Figure(backgroundcolor = RGBf(0.0, 0.0, 0.0), resolution = (ncol * W * scale, nrow * H * scale));\n",
    "\n",
    "N = nrow * ncol;\n",
    "n = 1;\n",
    "for row ∈ 1:nrow\n",
    "    for col ∈ 1:ncol\n",
    "        gray_image = (reshape(xtrain[:, :, :, n], 28, 28))\n",
    "        image(f[row, col], gray_image, axis = (aspect = DataAspect(), yreversed = true, title = \"Digit: $(ytrain[n])\", titlecolor=:white));\n",
    "        n += 1;\n",
    "    end\n",
    "end\n",
    "\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show random image in detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_ = floor(Int, rand() * n_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 50;\n",
    "\n",
    "f = Figure(backgroundcolor = RGBf(0.0, 0.0, 0.0), resolution = (ncol * W * scale, nrow * H * scale));\n",
    "\n",
    "\n",
    "gray_image = (reshape(xtrain[:, :, :, random_], 28, 28))\n",
    "image(f[1, 1], gray_image, axis = (aspect = DataAspect(), yreversed = true, title = \"Digit: $(ytrain[random_])\", titlecolor=:white, titlesize=200));\n",
    "\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "\n",
    "### Rescale pixel values\n",
    "\n",
    "We rescale the pixel values to the range [0, 1] to normalize the training data and faciliate the backpropagation process and convert the data to 32 bit floats that reduce memory requirements and computational cost while providing sufficient precision for our use case:\n",
    "\n",
    "In Flux MLDataset API all images pixels values are in the range [0, 1] already."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Label Encoding using Keras\n",
    "\n",
    "Print first ten labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Integer-valued labels:\\n\")\n",
    "print(ytrain[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain, ytest = onehotbatch(ytrain, 0:9), onehotbatch(ytest, 0:9);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Flow Experiment Tracking\n",
    "\n",
    "MLflow is a platform to streamline machine learning development, including tracking experiments, packaging code into reproducible runs, and sharing and deploying models. MLflow offers a set of lightweight APIs that can be used with any existing machine learning application or library (TensorFlow, PyTorch, XGBoost, etc), wherever you currently run ML code (e.g. in notebooks, standalone applications or the cloud). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyCall\n",
    "\n",
    "mlflow = pyimport(\"mlflow\")\n",
    "\n",
    "MLF_EXPERIMENT_NAME = \"Digit Classification Wign LeNet5\"\n",
    "MLF_EXPERIMENT_ID = 0\n",
    "\n",
    "try\n",
    "    MLF_EXPERIMENT_ID = mlflow.get_experiment_by_name(MLF_EXPERIMENT_NAME).experiment_id\n",
    "catch e\n",
    "    MLF_EXPERIMENT_ID = mlflow.create_experiment(MLF_EXPERIMENT_NAME)\n",
    "end\n",
    "\n",
    "mlflow.set_experiment(experiment_id=MLF_EXPERIMENT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed-Forward NN\n",
    "\n",
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffnn = Chain(\n",
    "    Chain(\n",
    "        Flux.flatten,\n",
    "        Flux.Dense(H * W, 512, NNlib.relu),\n",
    "        Flux.Dropout(0.2),\n",
    "        Flux.Dense(512, 512, NNlib.relu),\n",
    "        Flux.Dropout(0.2),\n",
    "        Flux.Dense(512, 10),\n",
    "    ), NNlib.softmax\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Validation, Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLUtils: splitobs\n",
    "\n",
    "batchsize = 32;\n",
    "\n",
    "(xtrain, ytrain), (xvalidation, yvalidation) = splitobs((xtrain, ytrain), at=0.80, shuffle=true);\n",
    "\n",
    "train_loader = DataLoader((xtrain, ytrain), batchsize=batchsize, shuffle=true);\n",
    "validation_loader = DataLoader((xvalidation, yvalidation), batchsize=batchsize, shuffle=true);\n",
    "\n",
    "test_loader = DataLoader((xtest, ytest),  batchsize=batchsize);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100;\n",
    "device = cpu;\n",
    "\n",
    "optimiser = Flux.RMSProp();\n",
    "model = ffnn |> device;\n",
    "loss = Flux.logitcrossentropy;\n",
    "ps = Flux.params(model);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Baseline Classification Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params(model) = sum(length, Flux.params(model)) \n",
    "round4(x) = round(x, digits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "function eval_loss_accuracy(loader, model, device, phase)\n",
    "    l = 0f0\n",
    "    acc = 0\n",
    "    ntot = 0\n",
    "    for (x, y) in loader\n",
    "        x, y = x |> device, y |> device\n",
    "        ŷ = model(x)\n",
    "        l += loss(ŷ, y) * size(x)[end]        \n",
    "        acc += sum(onecold(ŷ |> cpu) .== onecold(y |> cpu))\n",
    "        ntot += size(x)[end]\n",
    "    end\n",
    "\n",
    "    loss_value = l / ntot |> round4;\n",
    "    accuracy = acc / ntot * 100 |> round4;\n",
    "\n",
    "    metrics_dict = Dict(\n",
    "        \"$phase accuracy\" => accuracy,\n",
    "        \"$phase loss\" => loss_value,\n",
    "    );\n",
    "\n",
    "    return metrics_dict;\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics_dict = eval_loss_accuracy(train_loader, model, device, \"train\");\n",
    "validation_metrics_dict = eval_loss_accuracy(validation_loader, model, device, \"validation\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()\n",
    "mlflow.start_run(run_name=\"FFNN\");\n",
    "for epoch ∈ 1:epochs\n",
    "\n",
    "    for (x, y) in train_loader\n",
    "        x, y = x |> device, y |> device;\n",
    "\n",
    "        gs = Flux.gradient(ps) do\n",
    "            ŷ = model(x);\n",
    "            loss(ŷ, y);\n",
    "        end\n",
    "\n",
    "        Flux.Optimise.update!(optimiser, ps, gs);\n",
    "    end\n",
    "\n",
    "    train_metrics_dict = eval_loss_accuracy(train_loader, model, device, \"train\");\n",
    "    validation_metrics_dict = eval_loss_accuracy(validation_loader, model, device, \"validation\"); \n",
    "\n",
    "    mlflow.log_metrics(train_metrics_dict, step=epoch);\n",
    "    mlflow.log_metrics(validation_metrics_dict, step=epoch);\n",
    "\n",
    "    # if args.checktime > 0 && epoch % args.checktime == 0\n",
    "    #     !ispath(args.savepath) && mkpath(args.savepath)\n",
    "    #     modelpath = joinpath(args.savepath, \"model.bson\") \n",
    "    #     let model = cpu(model) #return model to cpu before serialization\n",
    "    #         BSON.@save modelpath model epoch\n",
    "    #     end\n",
    "    #     @info \"Model saved in \\\"$(modelpath)\\\"\"\n",
    "    # end\n",
    "end\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = \"02_ffnn.bson\";\n",
    "let model = cpu(model) # return model to cpu before serialization\n",
    "    BSON.@save modelpath model\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV Results\n",
    "\n",
    "Run command `mlflow server -p 5001` to observe experiment tracking's results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet5\n",
    "\n",
    "### Model Architecture\n",
    "\n",
    "We can define a simplified version of LeNet5 that omits the original final layer containing radial basis functions as follows, using the default ‘valid’ padding and single step strides unless defined otherwise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function LeNet5(; imgsize=(28,28,1), nclasses=10) \n",
    "  out_conv_size = (imgsize[1] ÷ 4 - 3, imgsize[2] ÷ 4 - 3, 16);\n",
    "\n",
    "  return Chain(\n",
    "    Chain(\n",
    "    Conv((5, 5), imgsize[end]=>6, relu),\n",
    "    MaxPool((2, 2)),\n",
    "    Conv((5, 5), 6=>16, relu),\n",
    "    MaxPool((2, 2)),\n",
    "    flatten,\n",
    "    Dense(prod(out_conv_size), 120, relu), \n",
    "    Dense(120, 84, relu), \n",
    "    Dense(84, nclasses)),\n",
    "    softmax\n",
    "  )\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "η = 3e-4;            # learning rate\n",
    "λ = 0;               # L2 regularizer param, implemented as weight decay\n",
    "epochs = 100;        # number of epochs\n",
    "device = cpu;        # device to use\n",
    "model = LeNet5();    # model to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = ADAM(η) \n",
    "if λ > 0 # add weight decay, equivalent to L2 regularization\n",
    "    opoptimisert = Optimiser(WeightDecay(λ), optimiser)\n",
    "end\n",
    "\n",
    "model = model |> device;\n",
    "loss = Flux.logitcrossentropy;\n",
    "ps = Flux.params(model);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()\n",
    "mlflow.start_run(run_name=\"LeNet5\");\n",
    "for epoch ∈ 1:epochs\n",
    "\n",
    "    for (x, y) in train_loader\n",
    "        x, y = x |> device, y |> device;\n",
    "\n",
    "        gs = Flux.gradient(ps) do\n",
    "            ŷ = model(x);\n",
    "            loss(ŷ, y)\n",
    "        end\n",
    "\n",
    "        Flux.Optimise.update!(optimiser, ps, gs)\n",
    "    end\n",
    "\n",
    "    train_metrics_dict = eval_loss_accuracy(train_loader, model, device, \"train\")\n",
    "    validation_metrics_dict = eval_loss_accuracy(validation_loader, model, device, \"validation\") \n",
    "\n",
    "    mlflow.log_metrics(train_metrics_dict, step=epoch);\n",
    "    mlflow.log_metrics(validation_metrics_dict, step=epoch);\n",
    "\n",
    "    # if args.checktime > 0 && epoch % args.checktime == 0\n",
    "    #     !ispath(args.savepath) && mkpath(args.savepath)\n",
    "    #     modelpath = joinpath(args.savepath, \"model.bson\") \n",
    "    #     let model = cpu(model) #return model to cpu before serialization\n",
    "    #         BSON.@save modelpath model epoch\n",
    "    #     end\n",
    "    #     @info \"Model saved in \\\"$(modelpath)\\\"\"\n",
    "    # end\n",
    "end\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV Results\n",
    "\n",
    "On a single GPU, 50 epochs take around 2.5 minutes, resulting in a test accuracy of 99.09%, slightly below the same result as for the original LeNet5.\n",
    "\n",
    "Run command `mlflow server -p 5001` to observe experiment tracking's results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Classification Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics_dict = eval_loss_accuracy(test_loader, model, device, \"train\");\n",
    "test_metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "For comparison, a simple two-layer feedforward network achieves only 37.36% test accuracy. \n",
    "\n",
    "The LeNet5 improvement on MNIST is, in fact, modest. Non-neural methods have also achieved classification accuracies greater than or equal to 99%, including K-Nearest Neighbours or Support Vector Machines. CNNs really shine with more challenging datasets as we will see next."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f81bd9540777417bbcd25f4a0dbfc40af4eb92579579dbd9c9f026aa409e85e"
  },
  "kernelspec": {
   "display_name": "Julia 1.7.0",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
