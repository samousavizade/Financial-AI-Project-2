{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use Flux\n",
    "\n",
    "Flux is a library for machine learning geared towards high-performance production pipelines. It comes \"batteries-included\" with many useful tools built in, but also lets you use the full power of the Julia language where you need it. We follow a few key principles:\n",
    "\n",
    "- Doing the obvious thing. Flux has relatively few explicit APIs for features like regularisation or embeddings. Instead, writing down the mathematical form will work – and be fast.\n",
    "- Extensible by default. Flux is written to be highly extensible and flexible while being performant. Extending Flux is as simple as using your own code as part of the model you want - it is all high level Julia code. When in doubt, it’s well worth looking at the source. If you need something different, you can easily roll your own.\n",
    "- Performance is key. Flux integrates with high-performance AD tools such as Zygote.jl for generating fast code. Flux optimizes both CPU and GPU performance. Scaling workloads easily to multiple GPUs can be done with the help of Julia's GPU tooling and projects like DaggerFlux.jl.\n",
    "- Play nicely with others. Flux works well with Julia libraries from data frames and images to differential equation solvers, so you can easily build complex data processing pipelines that integrate Flux models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux, PlotlyJS, Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(1234);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CUDA\n",
    "# CUDA.functional()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layer = Dense(10, 5);\n",
    "tensor = rand(10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = \"results\";\n",
    "!isdir(results_path) && mkdir(results_path);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Data\n",
    "\n",
    "### Generate random data\n",
    "\n",
    "The target `y` represents two classes generated by two circular distribution that are not linearly separable because class 0 surrounds class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset params\n",
    "N = 50000;\n",
    "factor = 0.1;\n",
    "noise = 0.1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted From SyntheticDatasets\n",
    "using DataFrames\n",
    "using PyCall\n",
    "sk = pyimport(\"sklearn.datasets\")\n",
    "\n",
    "function convert(features::Array{T, 2}, labels::Array{D, 1})::DataFrame where {T <: Number, D <: Number}\n",
    "    df = DataFrame()\n",
    "\n",
    "    for i = 1:size(features)[2]\n",
    "        df[!, Symbol(\"feature_$(i)\")] = eltype(features)[]\n",
    "    end\n",
    "    \n",
    "    df[!, :label] = eltype(labels)[]\n",
    "    \n",
    "    for label in unique(labels)\n",
    "        for i in findall(r->r == label, labels)\n",
    "            push!(df, (features[i, :]... , label))\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return df\n",
    "end\n",
    "\n",
    "function convert(features::Array{T, 2}, labels::Array{D, 2})::DataFrame where {T <: Number, D <: Number}\n",
    "    df = DataFrame()\n",
    "\n",
    "    for i = 1:size(features)[2]\n",
    "        df[!, Symbol(\"feature_$(i)\")] = eltype(features)[]\n",
    "    end\n",
    "\n",
    "    for i = 1:size(labels)[2]\n",
    "        df[!, Symbol(\"label_$(i)\")] = eltype(labels)[]\n",
    "    end\n",
    "    \n",
    "    for row in 1:size(features)[1]\n",
    "        push!(df, (features[row, :]... , labels[row, :]...))\n",
    "    end\n",
    "    \n",
    "    return df\n",
    "end\n",
    "\n",
    "\n",
    "(features, labels) = sk.make_circles(\n",
    "    n_samples=N,\n",
    "    shuffle=true,\n",
    "    noise=noise,\n",
    "    factor=factor\n",
    ");\n",
    "\n",
    "circles = convert(features, labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_column_name = \"label\"\n",
    "\n",
    "y = circles[:, [labels_column_name]];\n",
    "y = Matrix(y);\n",
    "\n",
    "X = select!(circles, Not(labels_column_name));\n",
    "X = Matrix(X);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define outcome matrix\n",
    "Y = zeros(Float64, (N, 2));\n",
    "for c ∈ [0, 1]\n",
    "    # mask = collect(Iterators.flatten(y .== c))\n",
    "    mask = vec(y .== c)\n",
    "    Y[mask, c+1] .= 1.0\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Shape of: X: $(size(X)) | Y: $(size(Y)) | y: $(size(y))\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PlotlyJS\n",
    "using DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set PlotlyJS Theme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates.default = \"plotly_dark\";\n",
    "PlotlyJS.templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(\n",
    "    X1=X[:, 1],\n",
    "    X2=X[:, 2],\n",
    "    Label=y[:, 1];\n",
    ");\n",
    "\n",
    "# ax = PlotlyJS.plot(\n",
    "#     df,\n",
    "#     x=:X1,\n",
    "#     y=:X2,\n",
    "#     m=1,\n",
    "#     color=:Label,\n",
    "#     kind=\"scatter\",\n",
    "#     mode=\"markers\",\n",
    "#     labels=Dict(\n",
    "#         :X1 => \"X\",\n",
    "#         :X2 => \"Y\",\n",
    "#         :Label => \"Labels\"\n",
    "#     ),\n",
    "#     marker=attr(size=8, line=attr(width=1, color=\"DarkSlateGrey\")),\n",
    "#     PlotlyJS.Layout(\n",
    "#         title=\"Circles Dataset Visualization\",\n",
    "#         width=600, height=600,\n",
    "#     )\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Flux Model\n",
    "\n",
    "[[FLUX_TUTORIAL_MODEL_BUILDING]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Chain(\n",
    "    Dense(2, 3, Flux.σ),\n",
    "    Dense(3, 2),\n",
    "    softmax\n",
    ");\n",
    "\n",
    "Flux.loadparams!(model, map(p -> p .= randn.(), Flux.params(model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - FLUX_TUTORIAL_MODEL_ARCHITECTURE\n",
    "\n",
    "2 - FLUX_TUTORIAL_MODEL_ARCHITECTURE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Flow Experiment Tracking\n",
    "\n",
    "MLflow is a platform to streamline machine learning development, including tracking experiments, packaging code into reproducible runs, and sharing and deploying models. MLflow offers a set of lightweight APIs that can be used with any existing machine learning application or library (TensorFlow, PyTorch, XGBoost, etc), wherever you currently run ML code (e.g. in notebooks, standalone applications or the cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyCall\n",
    "\n",
    "mlflow = pyimport(\"mlflow\")\n",
    "\n",
    "MLF_EXPERIMENT_NAME = \"How To Use Flux Julia\"\n",
    "MLF_EXPERIMENT_ID = 0\n",
    "\n",
    "try\n",
    "    MLF_EXPERIMENT_ID = mlflow.get_experiment_by_name(MLF_EXPERIMENT_NAME).experiment_id\n",
    "catch e\n",
    "    MLF_EXPERIMENT_ID = mlflow.create_experiment(MLF_EXPERIMENT_NAME)\n",
    "end\n",
    "\n",
    "mlflow.set_experiment(experiment_id=MLF_EXPERIMENT_ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux, MLUtils, MLBase\n",
    "function performance_evaluation_dict(\n",
    "    ŷ,\n",
    "    y,\n",
    "    phase,\n",
    ")\n",
    "    ŷ, y = vec(ŷ), vec(y);\n",
    "\n",
    "    error_rate = MLBase.errorrate(ŷ, y);\n",
    "\n",
    "    accuracy = MLBase.correctrate(ŷ, y);\n",
    "\n",
    "    loss = Flux.binarycrossentropy(ŷ, y);\n",
    "\n",
    "    roc_nums::ROCNums = MLBase.roc(ŷ, y);\n",
    "\n",
    "    fpr = MLBase.false_positive_rate(roc_nums);\n",
    "    fnr = MLBase.false_negative_rate(roc_nums);\n",
    "\n",
    "    f1_score = MLBase.f1score(roc_nums);\n",
    "\n",
    "    metrics_dict = Dict(\n",
    "        \"$phase error_rate\" => error_rate,\n",
    "        \"$phase accuracy\" => accuracy,\n",
    "        \"$phase loss\" => loss,\n",
    "        \"$phase fpr\" => fpr,\n",
    "        \"$phase fnr\" => fnr,\n",
    "        \"$phase f1_score\" => f1_score,\n",
    "    );\n",
    "\n",
    "    metrics_dict\n",
    "end;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(x) = map(x -> x[1] - 1, argmax(model(x), dims=1));\n",
    "epochs = 10\n",
    "optimiser = Flux.RMSProp();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Train Validation Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLBase, MLUtils, Flux\n",
    "\n",
    "function train_loop(train_data, model, optimiser, batch_size)\n",
    "    Flux.trainmode!(model)\n",
    "\n",
    "    for (x, y) ∈ eachobs(train_data, batchsize=batch_size)\n",
    "        # ... train supervised model on minibatches here\n",
    "        grads = gradient(Flux.params(model)) do\n",
    "            training_loss = Flux.binarycrossentropy(model(x), y)\n",
    "\n",
    "            # Code inserted here will be differentiated, unless you need that gradient information\n",
    "            # it is better to do the work outside this block.\n",
    "\n",
    "            return training_loss\n",
    "        end\n",
    "\n",
    "        # Insert whatever code you want here that needs training_loss, e.g. logging.\n",
    "        # logging_callback(training_loss)\n",
    "        # Insert what ever code you want here that needs gradient.\n",
    "        # E.g. logging with TensorBoardLogger.jl as histogram so you can see if it is becoming huge.\n",
    "\n",
    "        Flux.update!(optimiser, Flux.params(model), grads)\n",
    "\n",
    "        # Here you might like to check validation set accuracy, and break out to do early stopping.\n",
    "    end\n",
    "\n",
    "    X, Y = train_data\n",
    "\n",
    "    Y = map(x -> x[1] - 1, argmax(Y, dims=1))\n",
    "    Ŷ = predict(X)\n",
    "\n",
    "    Y, Ŷ\n",
    "end;\n",
    "\n",
    "function test_loop(test_data, model, optimiser, batch_size)\n",
    "    Flux.testmode!(model)\n",
    "\n",
    "    for (x, y) ∈ eachobs(test_data, batchsize=batch_size)\n",
    "        # # ... train supervised model on minibatches here\n",
    "        # grads = gradient(Flux.params(model)) do\n",
    "        #     training_loss = Flux.binarycrossentropy(model(x), y)\n",
    "\n",
    "        #     # Code inserted here will be differentiated, unless you need that gradient information\n",
    "        #     # it is better to do the work outside this block.\n",
    "\n",
    "        #     return training_loss\n",
    "        # end\n",
    "\n",
    "        # # Insert whatever code you want here that needs training_loss, e.g. logging.\n",
    "        # # logging_callback(training_loss)\n",
    "        # # Insert what ever code you want here that needs gradient.\n",
    "        # # E.g. logging with TensorBoardLogger.jl as histogram so you can see if it is becoming huge.\n",
    "\n",
    "        # Flux.update!(optimiser, Flux.params(model), grads)\n",
    "\n",
    "        # # Here you might like to check validation set accuracy, and break out to do early stopping.\n",
    "    end\n",
    "\n",
    "    X, Y = test_data\n",
    "\n",
    "    Y = map(x -> x[1] - 1, argmax(Y, dims=1))\n",
    "    Ŷ = predict(X)\n",
    "\n",
    "    Y, Ŷ\n",
    "end;\n",
    "\n",
    "\n",
    "X_ = X';\n",
    "Y_ = Y';\n",
    "\n",
    "# # shuffle observations\n",
    "Xs, Ys = shuffleobs((X_, Y_))\n",
    "\n",
    "# We leave out 15 % of the data for testing\n",
    "cv_data, test_data = splitobs((Xs, Ys); at=0.85)\n",
    "\n",
    "print(size(Y_))\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "# # Next we partition the data using a 10-fold scheme.\n",
    "for (k, (train_data, val_data)) ∈ enumerate(kfolds(cv_data; k=5))\n",
    "    mlflow.start_run(run_name=\"Fold $(k)\");\n",
    "\n",
    "    for epoch = 1:20\n",
    "\n",
    "        train_Y, train_Ŷ = train_loop(train_data, model, optimiser, batch_size)\n",
    "        val_Y, val_Ŷ = test_loop(val_data, model, optimiser, batch_size)\n",
    "\n",
    "        train_metrics_dict = performance_evaluation_dict(\n",
    "            train_Ŷ,\n",
    "            train_Y,\n",
    "            \"train\",\n",
    "        )\n",
    "\n",
    "        val_metrics_dict = performance_evaluation_dict(\n",
    "            val_Ŷ,\n",
    "            val_Y,\n",
    "            \"validation\",\n",
    "        )\n",
    "\n",
    "        # mlflow.log_params(hyperparameters_configs.to_dict())\n",
    "        mlflow.log_metrics(train_metrics_dict, step=epoch);\n",
    "        mlflow.log_metrics(val_metrics_dict, step=epoch);\n",
    "    end\n",
    "\n",
    "    mlflow.end_run()\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & Test Accuracy & Loss Per Epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run command `mlflow server -p 5001` to observe experiment tracking's results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = Flux.params(model);\n",
    "[size(p) for p in model_params]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Decision Boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualization of the decision boundary resembles the result from the manual network implementation. The training with **Flux** runs a multiple faster, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function meshgrid(x, y)\n",
    "    mg = Iterators.product(x, y)\n",
    "\n",
    "    xx = first.(mg)\n",
    "    yy = last.(mg)\n",
    "\n",
    "    xx, yy\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 500 instead of 200 for more resulotion boundry in the coutour plot.\n",
    "n_vals = 500;\n",
    "x1 = range(-1.5, 1.5, n_vals);\n",
    "x2 = range(-1.5, 1.5, n_vals);\n",
    "# create the grid\n",
    "xx, yy = meshgrid(x1, x2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fill the feature space\n",
    "feature_space = zeros(n_vals, n_vals);\n",
    "f = false;\n",
    "for i ∈ 1:n_vals\n",
    "    for j ∈ 1:n_vals\n",
    "        X_ = [xx[i, j]; yy[i, j]];\n",
    "        result = predict(X_);\n",
    "\n",
    "        # if (result != [0])\n",
    "        #     print(result);\n",
    "        #     f = true;\n",
    "        #     break;\n",
    "        # end\n",
    "\n",
    "        # index = argmax(probabilities);\n",
    "        feature_space[i, j] = result[1];\n",
    "    end\n",
    "    # if (f)\n",
    "    #     break;\n",
    "    # end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrames.transform(df, :Label => ByRow(label -> label == 0 ? \"Outer Circle\" : \"Inner Circle\") => :State);\n",
    "\n",
    "alpha = 0.15;\n",
    "colorscale = [[0, \"rgba(0,0,255,$alpha)\"], [1, \"rgba(255,255,0,$alpha)\"]]\n",
    "\n",
    "PlotlyJS.plot([\n",
    "        contour(\n",
    "            x=x1, # horizontal axis\n",
    "            y=x2, # vertical axis\n",
    "            z=feature_space', # data\n",
    "\n",
    "            # contours_coloring=\"lines\",\n",
    "\n",
    "            # autocolorscale=true,\n",
    "            colorscale=colorscale,\n",
    "\n",
    "            line_width=1,\n",
    "            line_smoothing=0.85,\n",
    "            colorbar=attr(\n",
    "                title=\"Decision Boundry\", # title here\n",
    "                titleside=\"right\",\n",
    "                titlefont=attr(\n",
    "                    size=14,\n",
    "                    family=\"Arial, sans-serif\"),\n",
    "                thickness=25,\n",
    "                thicknessmode=\"pixels\",\n",
    "                len=0.8,\n",
    "                lenmode=\"fraction\",\n",
    "                outlinewidth=0,\n",
    "            ),\n",
    "\n",
    "            # Smooth Coloring based on Z (In this case Z = 0, 1)\n",
    "            contours=attr(\n",
    "                coloring =\"heatmap\",\n",
    "                # showlabels = true, # show labels on contours\n",
    "                labelfont = attr( # label font properties\n",
    "                    size = 12,\n",
    "                    color = \"white\",\n",
    "                )\n",
    "            )\n",
    "        ),\n",
    "        \n",
    "        PlotlyJS.scatter(\n",
    "            df,\n",
    "            x=:X1,\n",
    "            y=:X2,\n",
    "\n",
    "            # NOTE: marker_color for scatter() and color for plot()\n",
    "            marker_color=:Label,\n",
    "            \n",
    "            text=:State,\n",
    "            \n",
    "            mode=\"markers\",\n",
    "            labels=Dict(\n",
    "                :X1 => \"X\",\n",
    "                :X2 => \"Y\",\n",
    "                :Label => \"Labels\"\n",
    "            ),\n",
    "            marker=attr(size=8, line=attr(width=1, color=\"DarkSlateGrey\")),\n",
    "        ),\n",
    "        ],\n",
    "    PlotlyJS.Layout(\n",
    "        title=\"Circles Dataset Visualization\",\n",
    "        width=700, height=700,\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.0",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
