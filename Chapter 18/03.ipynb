{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10 Image Classification\n",
    "\n",
    "Fast-forward to 2012, and we move on to the deeper and more modern VGG16 architecture. We will use the CIFAR10 dataset that uses 60,000 ImageNet samples, compressed to 32x32 pixel resolution (from the original 224x224), but still with three color channels. There are only 10 of the original 1,000 classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Flux.Data: DataLoader\n",
    "using Flux.Optimise: Optimiser, WeightDecay\n",
    "using Flux: onehotbatch, onecold, flatten\n",
    "using Flux.Losses: logitcrossentropy\n",
    "using Statistics, Random\n",
    "using Logging: with_logger\n",
    "using TensorBoardLogger: TBLogger, tb_overwrite, set_step!, set_step_increment!\n",
    "using ProgressMeter: @showprogress\n",
    "using BSON\n",
    "using CUDA\n",
    "using MLDatasets: CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST Database\n",
    "\n",
    "CIFAR10 can also be downloaded from MLDatasets Lib, and we similarly rescale the pixel values and one-hot encode the ten class labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = CIFAR10(Tx=Float64, split=:train);\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = CIFAR10(Tx=Float64, split=:test);\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLUtils: shuffleobs\n",
    "\n",
    "xtrain, ytrain = train[:];\n",
    "xtest, ytest = test[:];\n",
    "\n",
    "xtrain = xtrain[:, :, :, 1:1000];\n",
    "ytrain = ytrain[1:1000];\n",
    "xtest = xtest[:, :, :, 1:250];\n",
    "ytest = ytest[1:250];\n",
    "\n",
    "n_train = size(xtrain, 4);\n",
    "n_test = size(xtest, 4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The MNIST database has a training set of $n_train examples.\\n\");\n",
    "print(\"The MNIST database has a test set of $n_test examples.\\n\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size(xtrain), size(xtest), size(ytrain), size(ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Data\n",
    "\n",
    "### Visualize the First 30 Training Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_labels = Dict(\n",
    "    0 => \"airplane\",\n",
    "    1 => \"automobile\",\n",
    "    2 => \"bird\",\n",
    "    3 => \"cat\",\n",
    "    4 => \"deer\",\n",
    "    5 => \"dog\",\n",
    "    6 => \"frog\",\n",
    "    7 => \"horse\",\n",
    "    8 => \"ship\",\n",
    "    9 => \"truck\",\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = length(cifar10_labels);\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CairoMakie, Images\n",
    "using Images: colorview, channelview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = H = 32;\n",
    "scale = 10;\n",
    "\n",
    "nrow, ncol = 5, 6;\n",
    "f = Figure(backgroundcolor = RGBf(0.0, 0.0, 0.0), resolution = (ncol * W * scale, nrow * H * scale));\n",
    "\n",
    "N = nrow * ncol;\n",
    "n = 1;\n",
    "for row ∈ 1:nrow\n",
    "    for col ∈ 1:ncol\n",
    "        ch_view = xtrain[:, :, :, n];\n",
    "        ch_view = permutedims(ch_view, (3, 1, 2));\n",
    "\n",
    "        color_view = Images.colorview(RGB, ch_view);\n",
    "        image(f[row, col], color_view, axis = (aspect = DataAspect(), yreversed = true, title = \"Label: $(cifar10_labels[ytrain[n]])\", titlecolor=:white, titlesize=24));\n",
    "        n += 1;\n",
    "    end\n",
    "end\n",
    "\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show random image in detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_ = floor(Int, rand() * n_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 50;\n",
    "\n",
    "f = Figure(backgroundcolor = RGBf(0.0, 0.0, 0.0), resolution = (ncol * W * scale, nrow * H * scale));\n",
    "\n",
    "ch_view = xtrain[:, :, :, random_];\n",
    "ch_view = permutedims(ch_view, (3, 1, 2));\n",
    "\n",
    "color_view = Images.colorview(RGB, ch_view);\n",
    "\n",
    "image(f[1, 1], color_view, axis = (aspect = DataAspect(), yreversed = true, title = \"Label: $(cifar10_labels[ytrain[n]])\", titlecolor=:white, titlesize=200));\n",
    "\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "\n",
    "### Rescale pixel values\n",
    "\n",
    "We rescale the pixel values to the range [0, 1] to normalize the training data and faciliate the backpropagation process and convert the data to 32 bit floats that reduce memory requirements and computational cost while providing sufficient precision for our use case:\n",
    "\n",
    "In Flux MLDataset API all images pixels values are in the range [0, 1] already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain, ytest = onehotbatch(ytrain, 0:9), onehotbatch(ytest, 0:9);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Flow Experiment Tracking\n",
    "\n",
    "MLflow is a platform to streamline machine learning development, including tracking experiments, packaging code into reproducible runs, and sharing and deploying models. MLflow offers a set of lightweight APIs that can be used with any existing machine learning application or library (TensorFlow, PyTorch, XGBoost, etc), wherever you currently run ML code (e.g. in notebooks, standalone applications or the cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyCall\n",
    "\n",
    "mlflow = pyimport(\"mlflow\")\n",
    "\n",
    "MLF_EXPERIMENT_NAME = \"Digit Classification Wign LeNet5\"\n",
    "MLF_EXPERIMENT_ID = 0\n",
    "\n",
    "try\n",
    "    MLF_EXPERIMENT_ID = mlflow.get_experiment_by_name(MLF_EXPERIMENT_NAME).experiment_id\n",
    "catch e\n",
    "    MLF_EXPERIMENT_ID = mlflow.create_experiment(MLF_EXPERIMENT_NAME)\n",
    "end\n",
    "\n",
    "mlflow.set_experiment(experiment_id=MLF_EXPERIMENT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed-Forward NN\n",
    "\n",
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffnn = Chain(\n",
    "    Chain(\n",
    "        Flux.flatten,\n",
    "        Flux.Dense(H * W * 3, 1000, NNlib.relu),\n",
    "        Flux.Dropout(0.2),\n",
    "        Flux.Dense(1000, 512, NNlib.relu),\n",
    "        Flux.Dropout(0.2),\n",
    "        Flux.Dense(512, 10),\n",
    "    ), NNlib.softmax\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Validation, Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size(xtrain), size(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLUtils: splitobs\n",
    "\n",
    "batchsize = 8;\n",
    "\n",
    "(xtrain, ytrain), (xvalidation, yvalidation) = splitobs((xtrain, ytrain), at=0.80, shuffle=true);\n",
    "\n",
    "train_loader = DataLoader((xtrain, ytrain), batchsize=batchsize, shuffle=true);\n",
    "validation_loader = DataLoader((xvalidation, yvalidation), batchsize=batchsize, shuffle=true);\n",
    "\n",
    "test_loader = DataLoader((xtest, ytest),  batchsize=batchsize);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100;\n",
    "device = gpu;\n",
    "\n",
    "optimiser = Flux.ADAM();\n",
    "model = ffnn |> device;\n",
    "loss = Flux.crossentropy;\n",
    "ps = Flux.params(model);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Baseline Classification Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params(model) = sum(length, Flux.params(model));\n",
    "round4(x) = round(x, digits=4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "function eval_loss_accuracy(loader, model, device, phase)\n",
    "    l = 0f0\n",
    "    acc = 0\n",
    "    ntot = 0\n",
    "    for (x, y) in loader\n",
    "        x, y = x |> device, y |> device\n",
    "        ŷ = model(x)\n",
    "        l += loss(ŷ, y) * size(x)[end]        \n",
    "        acc += sum(onecold(ŷ |> cpu) .== onecold(y |> cpu))\n",
    "        ntot += size(x)[end]\n",
    "    end\n",
    "\n",
    "    loss_value = l / ntot |> round4;\n",
    "    accuracy = acc / ntot * 100 |> round4;\n",
    "\n",
    "    metrics_dict = Dict(\n",
    "        \"$phase accuracy\" => accuracy,\n",
    "        \"$phase loss\" => loss_value,\n",
    "    );\n",
    "\n",
    "    return metrics_dict;\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics_dict = eval_loss_accuracy(train_loader, model, device, \"train\");\n",
    "validation_metrics_dict = eval_loss_accuracy(validation_loader, model, device, \"validation\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()\n",
    "mlflow.start_run(run_name=\"FFNN\");\n",
    "for epoch ∈ 1:epochs\n",
    "\n",
    "    for (x, y) in train_loader\n",
    "        x, y = x |> device, y |> device;\n",
    "\n",
    "        gs = Flux.gradient(ps) do\n",
    "            ŷ = model(x);\n",
    "            loss(ŷ, y);\n",
    "        end\n",
    "\n",
    "        Flux.Optimise.update!(optimiser, ps, gs);\n",
    "    end\n",
    "\n",
    "    train_metrics_dict = eval_loss_accuracy(train_loader, model, device, \"train\");\n",
    "    validation_metrics_dict = eval_loss_accuracy(validation_loader, model, device, \"validation\"); \n",
    "\n",
    "    mlflow.log_metrics(train_metrics_dict, step=epoch);\n",
    "    mlflow.log_metrics(validation_metrics_dict, step=epoch);\n",
    "\n",
    "    # if args.checktime > 0 && epoch % args.checktime == 0\n",
    "    #     !ispath(args.savepath) && mkpath(args.savepath)\n",
    "    #     modelpath = joinpath(args.savepath, \"model.bson\") \n",
    "    #     let model = cpu(model) #return model to cpu before serialization\n",
    "    #         BSON.@save modelpath model epoch\n",
    "    #     end\n",
    "    #     @info \"Model saved in \\\"$(modelpath)\\\"\"\n",
    "    # end\n",
    "end\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = \"03_ffnn.bson\";\n",
    "let model = cpu(model) # return model to cpu before serialization\n",
    "    BSON.@save modelpath model\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV Results\n",
    "\n",
    "Run command `mlflow server -p 5001` to observe experiment tracking's results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Classification Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics_dict = eval_loss_accuracy(test_loader, model, device, \"train\");\n",
    "test_metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network\n",
    "\n",
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Chain(\n",
    "    Chain(\n",
    "        Conv((2, 2), 3 => 16, relu, pad=(1, 1), stride=(1, 1)),\n",
    "        MaxPool((2,2)),\n",
    "        Conv((2, 2), 16 => 32, relu, pad=(1, 1), stride=(1, 1)),\n",
    "        MaxPool((2,2)),\n",
    "        Conv((2, 2), 32 => 64, relu, pad=(1, 1), stride=(1, 1)),\n",
    "        MaxPool((2,2)),\n",
    "        Dropout(0.3),\n",
    "        Flux.flatten,\n",
    "        Dense(64, 500, relu), \n",
    "        Dropout(0.4),\n",
    "        Dense(500, 10, relu),\n",
    "    ), \n",
    "    NNlib.softmax\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "η = 3e-4;            # learning rate\n",
    "λ = 1e-5;               # L2 regularizer param, implemented as weight decay\n",
    "epochs = 100;        # number of epochs\n",
    "device = gpu;        # device to use\n",
    "model = cnn;      # model to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = ADAM(η) \n",
    "if λ > 0 # add weight decay, equivalent to L2 regularization\n",
    "    opoptimisert = Optimiser(WeightDecay(λ), optimiser)\n",
    "end\n",
    "\n",
    "model = model |> device;\n",
    "loss = Flux.logitcrossentropy;\n",
    "ps = Flux.params(model);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()\n",
    "mlflow.start_run(run_name=\"CNN\");\n",
    "for epoch ∈ 1:epochs\n",
    "\n",
    "    for (x, y) in train_loader\n",
    "        x, y = x |> device, y |> device;\n",
    "\n",
    "        gs = Flux.gradient(ps) do\n",
    "            ŷ = model(x);\n",
    "            loss(ŷ, y)\n",
    "        end\n",
    "\n",
    "        Flux.Optimise.update!(optimiser, ps, gs)\n",
    "    end\n",
    "\n",
    "    train_metrics_dict = eval_loss_accuracy(train_loader, model, device, \"train\")\n",
    "    validation_metrics_dict = eval_loss_accuracy(validation_loader, model, device, \"validation\") \n",
    "\n",
    "    mlflow.log_metrics(train_metrics_dict, step=epoch);\n",
    "    mlflow.log_metrics(validation_metrics_dict, step=epoch);\n",
    "\n",
    "    # if args.checktime > 0 && epoch % args.checktime == 0\n",
    "    #     !ispath(args.savepath) && mkpath(args.savepath)\n",
    "    #     modelpath = joinpath(args.savepath, \"model.bson\") \n",
    "    #     let model = cpu(model) #return model to cpu before serialization\n",
    "    #         BSON.@save modelpath model epoch\n",
    "    #     end\n",
    "    #     @info \"Model saved in \\\"$(modelpath)\\\"\"\n",
    "    # end\n",
    "end\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV Results\n",
    "\n",
    "On a single GPU, 50 epochs take around 2.5 minutes, resulting in a test accuracy of 99.09%, slightly below the same result as for the original LeNet5.\n",
    "\n",
    "Run command `mlflow server -p 5001` to observe experiment tracking's results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Classification Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics_dict = eval_loss_accuracy(test_loader, model, device, \"train\");\n",
    "test_metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16\n",
    "\n",
    "We also need to simplify the VGG16 architecture in response to the lower dimensionality of CIFAR10 images relative to the ImageNet samples used in the competition. We use the original number of filters but make them smaller (see notebook for implementation). The summary shows the five convolutional layers followed by two fully-connected layers with frequent use of batch normalization, for a total of 21.5 million parameters:\n",
    "\n",
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```julia\n",
    "Chain(\n",
    "    Conv((3, 3), 3 => 64, relu, pad=(1, 1), stride=(1, 1)),\n",
    "    BatchNorm(64),\n",
    "    Conv((3, 3), 64 => 64, relu, pad=(1, 1), stride=(1, 1)),\n",
    "    BatchNorm(64),\n",
    "    MaxPool((2,2)),\n",
    "    Conv((3, 3), 64 => 128, relu, pad=(1, 1), stride=(1, 1)),\n",
    "    BatchNorm(128),\n",
    "    Conv((3, 3), 128 => 128, relu, pad=(1, 1), stride=(1, 1)),\n",
    "    BatchNorm(128),\n",
    "    MaxPool((2,2)),\n",
    "    Conv((3, 3), 128 => 256, relu, pad=(1, 1), stride=(1, 1)),\n",
    "    BatchNorm(256),\n",
    "    Conv((3, 3), 256 => 256, relu, pad=(1, 1), stride=(1, 1)),\n",
    "    BatchNorm(256),\n",
    "    Conv((3, 3), 256 => 256, relu, pad=(1, 1), stride=(1, 1)),\n",
    "    BatchNorm(256),\n",
    "    MaxPool((2,2)),\n",
    "    Conv((3, 3), 256 => 512, relu, pad=(1, 1), stride=(1, 1)),\n",
    "    BatchNorm(512),\n",
    "    Conv((3, 3), 512 => 512, relu, pad=(1, 1), stride=(1, 1)),\n",
    "    BatchNorm(512),\n",
    "    Conv((3, 3), 512 => 512, relu, pad=(1, 1), stride=(1, 1)),\n",
    "    BatchNorm(512),\n",
    "    MaxPool((2,2)),\n",
    "    Conv((3, 3), 512 => 512, relu, pad=(1, 1), stride=(1, 1)),\n",
    "    BatchNorm(512),\n",
    "    Conv((3, 3), 512 => 512, relu, pad=(1, 1), stride=(1, 1)),\n",
    "    BatchNorm(512),\n",
    "    Conv((3, 3), 512 => 512, relu, pad=(1, 1), stride=(1, 1)),\n",
    "    BatchNorm(512),\n",
    "    MaxPool((2,2)),\n",
    "    flatten,\n",
    "    Dense(512, 4096, relu),\n",
    "    Dropout(0.5),\n",
    "    Dense(4096, 4096, relu),\n",
    "    Dropout(0.5),\n",
    "    Dense(4096, 10)\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16 and VGG19 models\n",
    "function vgg16()\n",
    "    Chain(\n",
    "        Conv((3, 3), 3 => 64, relu, pad=(1, 1), stride=(1, 1)),\n",
    "        BatchNorm(64),\n",
    "        Conv((3, 3), 64 => 64, relu, pad=(1, 1), stride=(1, 1)),\n",
    "        BatchNorm(64),\n",
    "        MaxPool((2,2)),\n",
    "        Conv((3, 3), 64 => 128, relu, pad=(1, 1), stride=(1, 1)),\n",
    "        BatchNorm(128),\n",
    "        Conv((3, 3), 128 => 128, relu, pad=(1, 1), stride=(1, 1)),\n",
    "        BatchNorm(128),\n",
    "        MaxPool((2,2)),\n",
    "        Conv((3, 3), 128 => 256, relu, pad=(1, 1), stride=(1, 1)),\n",
    "        BatchNorm(256),\n",
    "        Conv((3, 3), 256 => 256, relu, pad=(1, 1), stride=(1, 1)),\n",
    "        BatchNorm(256),\n",
    "        Conv((3, 3), 256 => 256, relu, pad=(1, 1), stride=(1, 1)),\n",
    "        BatchNorm(256),\n",
    "        MaxPool((2,2)),\n",
    "        Conv((3, 3), 256 => 512, relu, pad=(1, 1), stride=(1, 1)),\n",
    "        BatchNorm(512),\n",
    "        Conv((3, 3), 512 => 512, relu, pad=(1, 1), stride=(1, 1)),\n",
    "        BatchNorm(512),\n",
    "        Conv((3, 3), 512 => 512, relu, pad=(1, 1), stride=(1, 1)),\n",
    "        BatchNorm(512),\n",
    "        MaxPool((2,2)),\n",
    "        Conv((3, 3), 512 => 512, relu, pad=(1, 1), stride=(1, 1)),\n",
    "        BatchNorm(512),\n",
    "        Conv((3, 3), 512 => 512, relu, pad=(1, 1), stride=(1, 1)),\n",
    "        BatchNorm(512),\n",
    "        Conv((3, 3), 512 => 512, relu, pad=(1, 1), stride=(1, 1)),\n",
    "        BatchNorm(512),\n",
    "        MaxPool((2,2)),\n",
    "        flatten,\n",
    "        Dense(512, 4096, relu),\n",
    "        Dropout(0.5),\n",
    "        Dense(4096, 4096, relu),\n",
    "        Dropout(0.5),\n",
    "        Dense(4096, 10)\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "η = 3e-4;            # learning rate\n",
    "λ = 1e-5;               # L2 regularizer param, implemented as weight decay\n",
    "epochs = 100;        # number of epochs\n",
    "device = gpu;        # device to use\n",
    "model = vgg16();       # model to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = ADAM(η) \n",
    "if λ > 0 # add weight decay, equivalent to L2 regularization\n",
    "    opoptimisert = Optimiser(WeightDecay(λ), optimiser)\n",
    "end\n",
    "\n",
    "model = model |> device;\n",
    "loss = Flux.logitcrossentropy;\n",
    "ps = Flux.params(model);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()\n",
    "mlflow.start_run(run_name=\"VGG16\");\n",
    "for epoch ∈ 1:epochs\n",
    "\n",
    "    for (x, y) in train_loader\n",
    "        x, y = x |> device, y |> device;\n",
    "\n",
    "        gs = Flux.gradient(ps) do\n",
    "            ŷ = model(x);\n",
    "            loss(ŷ, y)\n",
    "        end\n",
    "\n",
    "        Flux.Optimise.update!(optimiser, ps, gs)\n",
    "    end\n",
    "\n",
    "    train_metrics_dict = eval_loss_accuracy(train_loader, model, device, \"train\")\n",
    "    validation_metrics_dict = eval_loss_accuracy(validation_loader, model, device, \"validation\") \n",
    "\n",
    "    mlflow.log_metrics(train_metrics_dict, step=epoch);\n",
    "    mlflow.log_metrics(validation_metrics_dict, step=epoch);\n",
    "\n",
    "    # if args.checktime > 0 && epoch % args.checktime == 0\n",
    "    #     !ispath(args.savepath) && mkpath(args.savepath)\n",
    "    #     modelpath = joinpath(args.savepath, \"model.bson\") \n",
    "    #     let model = cpu(model) #return model to cpu before serialization\n",
    "    #         BSON.@save modelpath model epoch\n",
    "    #     end\n",
    "    #     @info \"Model saved in \\\"$(modelpath)\\\"\"\n",
    "    # end\n",
    "end\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV Results\n",
    "\n",
    "On a single GPU, 50 epochs take around 2.5 minutes, resulting in a test accuracy of 99.09%, slightly below the same result as for the original LeNet5.\n",
    "\n",
    "Run command `mlflow server -p 5001` to observe experiment tracking's results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Classification Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics_dict = eval_loss_accuracy(test_loader, model, device, \"train\");\n",
    "test_metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "For comparison, a simple two-layer feedforward network achieves only 37.36% test accuracy. \n",
    "\n",
    "The LeNet5 improvement on MNIST is, in fact, modest. Non-neural methods have also achieved classification accuracies greater than or equal to 99%, including K-Nearest Neighbours or Support Vector Machines. CNNs really shine with more challenging datasets as we will see next."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f81bd9540777417bbcd25f4a0dbfc40af4eb92579579dbd9c9f026aa409e85e"
  },
  "kernelspec": {
   "display_name": "Julia 1.7.0",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
